model_name: "facebook/esm2_t12_35M_UR50D"

lora:
  r: 8
  alpha: 16
  dropout: 0.1
  target_modules: ["query", "value"]

training:
  epochs: 3
  batch_size: 8
  learning_rate: 2e-4
  grad_accum_steps: 1
  fp16: true
  save_total_limit: 3
  save_strategy: "epoch"
  eval_strategy: "epoch"
  load_best_model_at_end: true

data:
  train_path: "data/tokenized/train_dataset"
  val_path: "data/tokenized/val_dataset"
  num_workers: 4
  pin_memory: true
  persistent_workers: true

wandb:
  project: "enzyme-classification-esm2"
  run_name: "esm2_lora_baseline"
