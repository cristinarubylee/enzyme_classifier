{
  "best_global_step": 27860,
  "best_metric": 0.9670840487457599,
  "best_model_checkpoint": "models/checkpoints\\checkpoint-27860",
  "epoch": 2.0,
  "eval_steps": 500,
  "global_step": 27860,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.03589375448671931,
      "grad_norm": 4.364210605621338,
      "learning_rate": 0.0001976118688681503,
      "loss": 1.3831,
      "step": 500
    },
    {
      "epoch": 0.07178750897343862,
      "grad_norm": 7.272689342498779,
      "learning_rate": 0.000195218951902369,
      "loss": 0.8409,
      "step": 1000
    },
    {
      "epoch": 0.10768126346015794,
      "grad_norm": 7.897853374481201,
      "learning_rate": 0.0001928260349365877,
      "loss": 0.6491,
      "step": 1500
    },
    {
      "epoch": 0.14357501794687724,
      "grad_norm": 15.160555839538574,
      "learning_rate": 0.00019043311797080643,
      "loss": 0.5312,
      "step": 2000
    },
    {
      "epoch": 0.17946877243359655,
      "grad_norm": 7.516565799713135,
      "learning_rate": 0.00018804020100502512,
      "loss": 0.4881,
      "step": 2500
    },
    {
      "epoch": 0.21536252692031588,
      "grad_norm": 4.160104751586914,
      "learning_rate": 0.00018564728403924386,
      "loss": 0.4342,
      "step": 3000
    },
    {
      "epoch": 0.25125628140703515,
      "grad_norm": 3.4205117225646973,
      "learning_rate": 0.00018325436707346255,
      "loss": 0.4287,
      "step": 3500
    },
    {
      "epoch": 0.2871500358937545,
      "grad_norm": 5.649907112121582,
      "learning_rate": 0.00018086145010768129,
      "loss": 0.398,
      "step": 4000
    },
    {
      "epoch": 0.3230437903804738,
      "grad_norm": 5.086979389190674,
      "learning_rate": 0.00017846853314189997,
      "loss": 0.3644,
      "step": 4500
    },
    {
      "epoch": 0.3589375448671931,
      "grad_norm": 2.73970627784729,
      "learning_rate": 0.00017607561617611868,
      "loss": 0.3584,
      "step": 5000
    },
    {
      "epoch": 0.3948312993539124,
      "grad_norm": 11.91581916809082,
      "learning_rate": 0.00017368269921033742,
      "loss": 0.3609,
      "step": 5500
    },
    {
      "epoch": 0.43072505384063176,
      "grad_norm": 12.335047721862793,
      "learning_rate": 0.0001712897822445561,
      "loss": 0.3658,
      "step": 6000
    },
    {
      "epoch": 0.46661880832735103,
      "grad_norm": 9.565715789794922,
      "learning_rate": 0.00016889686527877485,
      "loss": 0.3104,
      "step": 6500
    },
    {
      "epoch": 0.5025125628140703,
      "grad_norm": 10.85729694366455,
      "learning_rate": 0.00016650394831299354,
      "loss": 0.344,
      "step": 7000
    },
    {
      "epoch": 0.5384063173007897,
      "grad_norm": 0.5012436509132385,
      "learning_rate": 0.00016411103134721228,
      "loss": 0.267,
      "step": 7500
    },
    {
      "epoch": 0.574300071787509,
      "grad_norm": 1.0190155506134033,
      "learning_rate": 0.00016171811438143096,
      "loss": 0.2974,
      "step": 8000
    },
    {
      "epoch": 0.6101938262742282,
      "grad_norm": 11.043886184692383,
      "learning_rate": 0.00015932519741564967,
      "loss": 0.2775,
      "step": 8500
    },
    {
      "epoch": 0.6460875807609476,
      "grad_norm": 19.55397605895996,
      "learning_rate": 0.00015693228044986841,
      "loss": 0.2649,
      "step": 9000
    },
    {
      "epoch": 0.6819813352476669,
      "grad_norm": 3.256390333175659,
      "learning_rate": 0.0001545393634840871,
      "loss": 0.2936,
      "step": 9500
    },
    {
      "epoch": 0.7178750897343862,
      "grad_norm": 17.135528564453125,
      "learning_rate": 0.00015214644651830584,
      "loss": 0.2598,
      "step": 10000
    },
    {
      "epoch": 0.7537688442211056,
      "grad_norm": 5.323831081390381,
      "learning_rate": 0.00014975352955252453,
      "loss": 0.2626,
      "step": 10500
    },
    {
      "epoch": 0.7896625987078248,
      "grad_norm": 1.359493613243103,
      "learning_rate": 0.00014736061258674324,
      "loss": 0.2544,
      "step": 11000
    },
    {
      "epoch": 0.8255563531945441,
      "grad_norm": 4.30991792678833,
      "learning_rate": 0.00014496769562096195,
      "loss": 0.2267,
      "step": 11500
    },
    {
      "epoch": 0.8614501076812635,
      "grad_norm": 15.73705005645752,
      "learning_rate": 0.00014257477865518066,
      "loss": 0.2185,
      "step": 12000
    },
    {
      "epoch": 0.8973438621679828,
      "grad_norm": 7.691434383392334,
      "learning_rate": 0.00014018186168939938,
      "loss": 0.2212,
      "step": 12500
    },
    {
      "epoch": 0.9332376166547021,
      "grad_norm": 0.04796947166323662,
      "learning_rate": 0.0001377889447236181,
      "loss": 0.2288,
      "step": 13000
    },
    {
      "epoch": 0.9691313711414213,
      "grad_norm": 11.015028953552246,
      "learning_rate": 0.00013539602775783683,
      "loss": 0.2336,
      "step": 13500
    },
    {
      "epoch": 1.0,
      "eval_accuracy": 0.9481971606851208,
      "eval_loss": 0.2125290036201477,
      "eval_runtime": 219.5705,
      "eval_samples_per_second": 108.753,
      "eval_steps_per_second": 13.595,
      "step": 13930
    },
    {
      "epoch": 1.0050251256281406,
      "grad_norm": 1.7189459800720215,
      "learning_rate": 0.00013300311079205552,
      "loss": 0.1967,
      "step": 14000
    },
    {
      "epoch": 1.0409188801148601,
      "grad_norm": 1.7439470291137695,
      "learning_rate": 0.00013061019382627423,
      "loss": 0.1808,
      "step": 14500
    },
    {
      "epoch": 1.0768126346015794,
      "grad_norm": 0.008410544134676456,
      "learning_rate": 0.00012821727686049294,
      "loss": 0.1988,
      "step": 15000
    },
    {
      "epoch": 1.1127063890882987,
      "grad_norm": 3.879272937774658,
      "learning_rate": 0.00012582435989471165,
      "loss": 0.1857,
      "step": 15500
    },
    {
      "epoch": 1.148600143575018,
      "grad_norm": 0.11040864139795303,
      "learning_rate": 0.00012343144292893037,
      "loss": 0.1908,
      "step": 16000
    },
    {
      "epoch": 1.1844938980617372,
      "grad_norm": 11.854463577270508,
      "learning_rate": 0.00012103852596314908,
      "loss": 0.1806,
      "step": 16500
    },
    {
      "epoch": 1.2203876525484565,
      "grad_norm": 0.004622437059879303,
      "learning_rate": 0.00011864560899736781,
      "loss": 0.1687,
      "step": 17000
    },
    {
      "epoch": 1.2562814070351758,
      "grad_norm": 20.609853744506836,
      "learning_rate": 0.0001162526920315865,
      "loss": 0.1641,
      "step": 17500
    },
    {
      "epoch": 1.2921751615218953,
      "grad_norm": 2.9460902214050293,
      "learning_rate": 0.00011385977506580523,
      "loss": 0.1609,
      "step": 18000
    },
    {
      "epoch": 1.3280689160086145,
      "grad_norm": 0.01717245951294899,
      "learning_rate": 0.00011146685810002393,
      "loss": 0.164,
      "step": 18500
    },
    {
      "epoch": 1.3639626704953338,
      "grad_norm": 1.4805970191955566,
      "learning_rate": 0.00010907394113424266,
      "loss": 0.169,
      "step": 19000
    },
    {
      "epoch": 1.399856424982053,
      "grad_norm": 1.6843630075454712,
      "learning_rate": 0.00010668102416846136,
      "loss": 0.1743,
      "step": 19500
    },
    {
      "epoch": 1.4357501794687724,
      "grad_norm": 21.56645393371582,
      "learning_rate": 0.00010428810720268007,
      "loss": 0.1841,
      "step": 20000
    },
    {
      "epoch": 1.4716439339554919,
      "grad_norm": 1.2617604732513428,
      "learning_rate": 0.00010189519023689877,
      "loss": 0.1676,
      "step": 20500
    },
    {
      "epoch": 1.507537688442211,
      "grad_norm": 14.711886405944824,
      "learning_rate": 9.95022732711175e-05,
      "loss": 0.168,
      "step": 21000
    },
    {
      "epoch": 1.5434314429289304,
      "grad_norm": 4.395150184631348,
      "learning_rate": 9.710935630533621e-05,
      "loss": 0.1634,
      "step": 21500
    },
    {
      "epoch": 1.5793251974156497,
      "grad_norm": 0.6125059127807617,
      "learning_rate": 9.471643933955492e-05,
      "loss": 0.1591,
      "step": 22000
    },
    {
      "epoch": 1.615218951902369,
      "grad_norm": 0.05965202674269676,
      "learning_rate": 9.232352237377364e-05,
      "loss": 0.1477,
      "step": 22500
    },
    {
      "epoch": 1.6511127063890882,
      "grad_norm": 0.1078379824757576,
      "learning_rate": 8.993060540799235e-05,
      "loss": 0.1546,
      "step": 23000
    },
    {
      "epoch": 1.6870064608758075,
      "grad_norm": 0.20673902332782745,
      "learning_rate": 8.753768844221106e-05,
      "loss": 0.1433,
      "step": 23500
    },
    {
      "epoch": 1.722900215362527,
      "grad_norm": 0.5312508940696716,
      "learning_rate": 8.514477147642977e-05,
      "loss": 0.1657,
      "step": 24000
    },
    {
      "epoch": 1.758793969849246,
      "grad_norm": 1.5030722618103027,
      "learning_rate": 8.275185451064849e-05,
      "loss": 0.1683,
      "step": 24500
    },
    {
      "epoch": 1.7946877243359656,
      "grad_norm": 0.5032422542572021,
      "learning_rate": 8.03589375448672e-05,
      "loss": 0.1356,
      "step": 25000
    },
    {
      "epoch": 1.8305814788226848,
      "grad_norm": 0.019400987774133682,
      "learning_rate": 7.796602057908591e-05,
      "loss": 0.13,
      "step": 25500
    },
    {
      "epoch": 1.8664752333094041,
      "grad_norm": 0.011822453700006008,
      "learning_rate": 7.557310361330463e-05,
      "loss": 0.1497,
      "step": 26000
    },
    {
      "epoch": 1.9023689877961236,
      "grad_norm": 0.34902113676071167,
      "learning_rate": 7.318018664752332e-05,
      "loss": 0.1464,
      "step": 26500
    },
    {
      "epoch": 1.9382627422828427,
      "grad_norm": 0.16739797592163086,
      "learning_rate": 7.078726968174205e-05,
      "loss": 0.1552,
      "step": 27000
    },
    {
      "epoch": 1.9741564967695622,
      "grad_norm": 0.41901904344558716,
      "learning_rate": 6.839435271596076e-05,
      "loss": 0.1314,
      "step": 27500
    },
    {
      "epoch": 2.0,
      "eval_accuracy": 0.9670840487457599,
      "eval_loss": 0.14563874900341034,
      "eval_runtime": 227.3733,
      "eval_samples_per_second": 105.021,
      "eval_steps_per_second": 13.128,
      "step": 27860
    }
  ],
  "logging_steps": 500,
  "max_steps": 41790,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 3,
  "save_steps": 500,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": false
      },
      "attributes": {}
    }
  },
  "total_flos": 4.543071643869192e+16,
  "train_batch_size": 8,
  "trial_name": null,
  "trial_params": null
}
